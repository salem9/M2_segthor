{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     6,
     22
    ]
   },
   "source": [
    "## The preprocessing of THOR data\n",
    ">author: Tao He\n",
    "\n",
    ">Institution: Sichuan University\n",
    "\n",
    ">email: taohe@stu.scu.edu.cn\n",
    "\n",
    ">copyright: machine intelligence laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the source data download from https://ent.normandie-univ.fr/filex/get?k=oZgYIeT5lnbxhtHZ2u8\n",
    "### the data path organized like: \n",
    "```\n",
    "../data/data_source/Patient_01/GT.nii\n",
    "../data/data_source/Patient_01/Patient_01.nii\n",
    "```\n",
    "### or download from my Baidu Netdisk https://pan.baidu.com/s/1dQHYKIkUd5qCXIvdxSijNg; password: i41q\n",
    "### using this data, you should reference\n",
    ">@INPROCEEDINGS{trullo17isbi,\n",
    "\n",
    ">author = {Roger Trullo and C. Petitjean and Su Ruan and\n",
    "Bernard Dubray and Dong Nie and Dinggang Shen},\n",
    "\n",
    ">title = {Segmentation of Organs at Risk in Thoracic {CT} images using a SharpMask Architecture and Conditional Random Fields},\n",
    "\n",
    ">booktitle = {IEEE 14th International Symposium on Biomedical Imaging (ISBI)},\n",
    "\n",
    ">pages = {1003--1006},\n",
    "\n",
    ">year = {2017}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### processing the THOR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin processing data\n",
      "0 ../data/data_source/Patient_19\n",
      "1 ../data/data_source/Patient_34\n",
      "2 ../data/data_source/Patient_32\n",
      "3 ../data/data_source/Patient_35\n",
      "4 ../data/data_source/Patient_06\n",
      "5 ../data/data_source/Patient_14\n",
      "6 ../data/data_source/Patient_10\n",
      "7 ../data/data_source/Patient_37\n",
      "8 ../data/data_source/Patient_07\n",
      "9 ../data/data_source/Patient_01\n",
      "10 ../data/data_source/Patient_22\n",
      "11 ../data/data_source/Patient_40\n",
      "12 ../data/data_source/Patient_20\n",
      "13 ../data/data_source/Patient_11\n",
      "14 ../data/data_source/Patient_13\n",
      "15 ../data/data_source/Patient_26\n",
      "16 ../data/data_source/Patient_28\n",
      "17 ../data/data_source/Patient_21\n",
      "18 ../data/data_source/Patient_02\n",
      "19 ../data/data_source/Patient_36\n",
      "20 ../data/data_source/Patient_15\n",
      "21 ../data/data_source/Patient_12\n",
      "22 ../data/data_source/Patient_33\n",
      "23 ../data/data_source/Patient_38\n",
      "24 ../data/data_source/Patient_16\n",
      "25 ../data/data_source/Patient_08\n",
      "26 ../data/data_source/Patient_24\n",
      "27 ../data/data_source/Patient_05\n",
      "28 ../data/data_source/Patient_31\n",
      "29 ../data/data_source/Patient_09\n",
      "30 ../data/data_source/Patient_25\n",
      "31 ../data/data_source/Patient_39\n",
      "32 ../data/data_source/Patient_29\n",
      "33 ../data/data_source/Patient_17\n",
      "34 ../data/data_source/Patient_03\n",
      "35 ../data/data_source/Patient_04\n",
      "36 ../data/data_source/Patient_30\n",
      "37 ../data/data_source/Patient_23\n",
      "38 ../data/data_source/Patient_18\n",
      "39 ../data/data_source/Patient_27\n",
      "data mean is 0.119740\n",
      "data std is 0.017993\n",
      "total data size is 7340.000000\n",
      "processing data end !\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "import pdb\n",
    "\n",
    "\n",
    "def truncated_range(img):\n",
    "    max_hu = 384\n",
    "    min_hu = -384\n",
    "    img[np.where(img > max_hu)] = max_hu\n",
    "    img[np.where(img < min_hu)] = min_hu\n",
    "    return (img - min_hu) / (max_hu - min_hu) * 255.\n",
    "\n",
    "\n",
    "path = '../data/data_source/'\n",
    "save_path = '../data/data_npy/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "files = os.listdir(path)\n",
    "count = 0\n",
    "print('begin processing data')\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "total_imgs = []\n",
    "\n",
    "for i, volume in enumerate(files):\n",
    "    cur_file = os.path.join(path, volume)\n",
    "    print(i, cur_file)\n",
    "    cur_save_path = os.path.join(save_path, volume)\n",
    "    if not os.path.exists(cur_save_path):\n",
    "        os.makedirs(cur_save_path)\n",
    "    img = nib.load(os.path.join(cur_file, volume + '.nii'))\n",
    "    img = np.array(img.get_data())\n",
    "    label = nib.load(os.path.join(cur_file, 'GT.nii'))\n",
    "    label = np.array(label.get_data())\n",
    "    img = truncated_range(img)\n",
    "\n",
    "    for idx in range(img.shape[2]):\n",
    "        if idx == 0 or idx == img.shape[2] - 1:\n",
    "            continue\n",
    "        # 2.5D data, using adjacent 3 images\n",
    "        cur_img = img[:, :, idx - 1:idx + 2].astype('uint8')\n",
    "        total_imgs.append(cur_img)\n",
    "        cur_label = label[:, :, idx].astype('uint8')\n",
    "        count += 1\n",
    "#         np.save(\n",
    "#             os.path.join(cur_save_path,\n",
    "#                          volume + '_' + str(idx) + '_image.npy'), cur_img)\n",
    "#         np.save(\n",
    "#             os.path.join(cur_save_path,\n",
    "#                          volume + '_' + str(idx) + '_label.npy'), cur_label)\n",
    "    \n",
    "    total_imgs = np.stack(total_imgs, 3) / 255.\n",
    "    means.append(np.mean(total_imgs))\n",
    "    stds.append(np.std(total_imgs))\n",
    "    total_imgs = []\n",
    "\n",
    "print('data mean is %f' % np.mean(means))\n",
    "print('data std is %f' % np.std(stds))\n",
    "print('total data size is %f' % count)\n",
    "print('processing data end !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
